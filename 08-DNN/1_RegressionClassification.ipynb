{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-RegressionClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMXqCEY65Kq0fZVBZBu9PW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntmai03/DataAnalysisProject/blob/main/08-DNN/1_RegressionClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# <font color='#f78fb3'> **1 Setup**<br> </font> "
      ],
      "metadata": {
        "id": "3dh94P6jPUji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxct6D9UPLeM"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "import sklearn.decomposition as dec\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as PathEffects\n",
        "# import seaborn to make nice plots\n",
        "import seaborn as sns\n",
        "\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# <font color='#f78fb3'> **2 Regression**<br> </font> "
      ],
      "metadata": {
        "id": "YG7ad6P8bcnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#f78fb3'> <font color='#f9ca24'>**3.1 California housing**<br> </font>  "
      ],
      "metadata": {
        "id": "-nso-hQYbjTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Prepare data**</font>"
      ],
      "metadata": {
        "id": "Zmx4TZgEbvw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BgtHXZbFWhA",
        "outputId": "9e5fff65-47b9-4a5c-d3b8-139ed138db26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11610, 8), (5160, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6z_cctGovVG",
        "outputId": "4d383f68-5fc9-4daa-965e-91ebb891f782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "           37.88      , -122.23      ],\n",
              "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "           37.86      , -122.22      ],\n",
              "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "           37.85      , -122.24      ],\n",
              "        ...,\n",
              "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "           39.43      , -121.22      ],\n",
              "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "           39.43      , -121.32      ],\n",
              "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "           39.37      , -121.24      ]]),\n",
              " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
              " 'frame': None,\n",
              " 'target_names': ['MedHouseVal'],\n",
              " 'feature_names': ['MedInc',\n",
              "  'HouseAge',\n",
              "  'AveRooms',\n",
              "  'AveBedrms',\n",
              "  'Population',\n",
              "  'AveOccup',\n",
              "  'Latitude',\n",
              "  'Longitude'],\n",
              " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Construction Phase**</font>"
      ],
      "metadata": {
        "id": "G63jxlOLb37h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "        keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WJFVywvH1Gi",
        "outputId": "2baa94cb-9a70-443a-dcce-7b6f74f3d0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 30)                270       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "\n",
        "# compile\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "# model.compile(optimizer='rmsprop', loss='mse')\n",
        "# using checkpoint to save the best model\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"california_housing_model2.h5\", save_best_only=True)\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb])\n",
        "# Using Callbacks during Training\n",
        "model = keras.models.load_model(\"california_housing_model2.h5\")  #  rollback to best model\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "mse_train = model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWk4h3BMOWUJ",
        "outputId": "878781a5-d649-4d3c-b9e0-13681f1b2352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 3s 3ms/step - loss: 1.8866 - val_loss: 0.7126\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6880\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.4951\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 0.4861\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - val_loss: 0.4554\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4396\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4507\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3997\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.3956\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.3916\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3937\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.3809\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.3850\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.3809\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4003\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing an optimizer and loss\n",
        "\n",
        "Keep in mind what kind of problem you are trying to solve:\n",
        "\n",
        "    # For a multi-class classification problem\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # For a binary classification problem\n",
        "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # For a mean squared error regression problem\n",
        "    model.compile(optimizer='rmsprop', loss='mse')"
      ],
      "metadata": {
        "id": "dcsZWLWesn7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"california_housing_model2.h5\", save_best_only=True)\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[val_train_ratio_cb, checkpoint_cb])\n",
        "model = keras.models.load_model(\"california_housing_model2.h5\")  #  rollback to best model\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "mse_train = model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX0fX4BKO111",
        "outputId": "4549fd7a-b371-4a58-a3b7-6b8d9928c719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "356/363 [============================>.] - ETA: 0s - loss: 1.9089\n",
            "val/train: 0.38\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.8866 - val_loss: 0.7126\n",
            "Epoch 2/20\n",
            "361/363 [============================>.] - ETA: 0s - loss: 0.6573\n",
            "val/train: 1.05\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6577 - val_loss: 0.6880\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - ETA: 0s - loss: 0.5934\n",
            "val/train: 0.98\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.5803\n",
            "Epoch 4/20\n",
            "362/363 [============================>.] - ETA: 0s - loss: 0.5544\n",
            "val/train: 0.93\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5166\n",
            "Epoch 5/20\n",
            "354/363 [============================>.] - ETA: 0s - loss: 0.5263\n",
            "val/train: 0.93\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.4895\n",
            "Epoch 6/20\n",
            "340/363 [===========================>..] - ETA: 0s - loss: 0.5023\n",
            "val/train: 0.98\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5033 - val_loss: 0.4951\n",
            "Epoch 7/20\n",
            "339/363 [===========================>..] - ETA: 0s - loss: 0.4857\n",
            "val/train: 1.00\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 0.4861\n",
            "Epoch 8/20\n",
            "337/363 [==========================>...] - ETA: 0s - loss: 0.4698\n",
            "val/train: 0.97\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4709 - val_loss: 0.4554\n",
            "Epoch 9/20\n",
            "361/363 [============================>.] - ETA: 0s - loss: 0.4588\n",
            "val/train: 0.96\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4413\n",
            "Epoch 10/20\n",
            "355/363 [============================>.] - ETA: 0s - loss: 0.4473\n",
            "val/train: 0.98\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4379\n",
            "Epoch 11/20\n",
            "358/363 [============================>.] - ETA: 0s - loss: 0.4397\n",
            "val/train: 1.00\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4396\n",
            "Epoch 12/20\n",
            "359/363 [============================>.] - ETA: 0s - loss: 0.4317\n",
            "val/train: 1.04\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4507\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - ETA: 0s - loss: 0.4261\n",
            "val/train: 0.94\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.3997\n",
            "Epoch 14/20\n",
            "360/363 [============================>.] - ETA: 0s - loss: 0.4207\n",
            "val/train: 0.94\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.3956\n",
            "Epoch 15/20\n",
            "359/363 [============================>.] - ETA: 0s - loss: 0.4170\n",
            "val/train: 0.94\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4155 - val_loss: 0.3916\n",
            "Epoch 16/20\n",
            "360/363 [============================>.] - ETA: 0s - loss: 0.4111\n",
            "val/train: 0.96\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3937\n",
            "Epoch 17/20\n",
            "355/363 [============================>.] - ETA: 0s - loss: 0.4080\n",
            "val/train: 0.93\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.3809\n",
            "Epoch 18/20\n",
            "354/363 [============================>.] - ETA: 0s - loss: 0.4054\n",
            "val/train: 0.94\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.3793\n",
            "Epoch 19/20\n",
            "361/363 [============================>.] - ETA: 0s - loss: 0.4007\n",
            "val/train: 0.96\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.3850\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - ETA: 0s - loss: 0.3980\n",
            "val/train: 0.96\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.3809\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4003\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.params)\n",
        "print(history.epoch)\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlEFTHIvJPHy",
        "outputId": "7cac1e89-c655-4425-fbb4-a13e56e8e0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 20, 'steps': 363}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Prediction**</font>"
      ],
      "metadata": {
        "id": "CWfYXGvcc8D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n",
        "y_pred[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jOKFUecc1wf",
        "outputId": "f4232957-5d23-4343-e567-257a9eba734b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5147517],\n",
              "       [1.8584764],\n",
              "       [3.3048759]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2i-JrMzdDPY",
        "outputId": "b2cc25aa-0b0a-4328-ef35-9e532ffa5bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.477  , 0.458  , 5.00001])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "test_predictions = model.predict(X_test)\n",
        "print(test_predictions[0:5])\n",
        "\n",
        "# Calculate error\n",
        "pred_df = pd.DataFrame(y_test, columns=['Test Y'])\n",
        "test_predictions = pd.Series(test_predictions.reshape(300,))\n",
        "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
        "pred_df.columns = ['Test Y', 'Model Prediction']\n",
        "pred_df['Error'] = pred_df['Test Y'] - pred_df['Model Prediction']\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "woAMc1NrtPhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Performance Evaluation**</font>"
      ],
      "metadata": {
        "id": "kdA4Q2n0cI0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pd.DataFrame(history.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "VGOwsZjQcBVa",
        "outputId": "4d8c36aa-7bf8-496c-d83a-91c8e774f091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = model.evaluate(X_test, y_test)\n",
        "mse_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJL6Fzu2cTqH",
        "outputId": "eb4c6678-1e5b-4ba5-ec14-eb102f7f0047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4003303050994873"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
        "\n",
        "# Prediction\n",
        "test_predictions = model.predict(X_test)\n",
        "print(model.metrics_names)\n",
        "\n",
        "# Train score, test score\n",
        "training_score = model.evaluate(X_train, y_train, verbose=0)\n",
        "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(training_score, test_score)\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = mean_squared_error(y_test, test_predictions)\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, test_predictions)\n",
        "print(\"MAE: %.3f\"  % mae)\n",
        "      \n",
        "# r2 - coefficient of determination\n",
        "r2 = explained_variance_score(y_test, test_predictions)\n",
        "print(\"r2: %.3f\" %r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC61NxTaJze6",
        "outputId": "5cad6baa-8a12-4c0f-d7ff-04216ee67e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss']\n",
            "0.40156564116477966 0.4003303050994873\n",
            "RMSE: 0.633\n",
            "MSE: 0.400\n",
            "MAE: 0.452\n",
            "r2: 0.698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Saving and Restoring**</font>"
      ],
      "metadata": {
        "id": "rzKHfJh0fUTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"california_housing_model1.h5\")\n",
        "model = keras.models.load_model(\"california_housing_model1.h5\")\n",
        "model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmfeUJa5dF5f",
        "outputId": "97b3a37f-02da-4be5-fced-74224de3a9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5147517],\n",
              "       [1.8584764],\n",
              "       [3.3048759]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"my_keras_weights.ckpt\")\n",
        "model.load_weights(\"my_keras_weights.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjsuBbExfmqF",
        "outputId": "486efcc7-0ee4-490c-d7f2-dc4cf89231a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f220273ff90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Hyperparameter Tuning & Early Stopping**</font>"
      ],
      "metadata": {
        "id": "x4CshJNAgVB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dense(1))\n",
        "  optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "  model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "hMa72CGtSOZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4to0HVpSVgPG",
        "outputId": "9ede5aae-4f7e-4778-a16a-ccddeb128f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.0896 - val_loss: 20.7721\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7606 - val_loss: 5.0266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5490\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.4188\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4338 - val_loss: 0.4129\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4004\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.3944\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.3961\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4071\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3855\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4136\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3818\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.3829\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3739\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.4022\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.3873\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3768\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4191\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4237\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3980\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3473\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3921\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3566\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.4191\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3722\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3948\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3423\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.3454\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3417\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3379\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3419\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3705\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3660\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3563 - val_loss: 0.3803\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3766\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3548 - val_loss: 0.3814\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3385\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3657\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3576\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3358\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3317\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3564\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3522\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4581\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3808\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3539\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3721\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3336\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.4011\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3271\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3348\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3492\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3401\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3274\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3437 - val_loss: 0.3296\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3307\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3252\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3242\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3254\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3659\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3379\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3272\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3242\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3661\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3284\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3243\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3372\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f220273fcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = keras_reg.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EyFAq47jpTe",
        "outputId": "4361d09b-efab-41df-cc32-b29b10fa5cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGnMN-jmXAkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(10, 30).tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
        "\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=10,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdD4ppCjqHQ8",
        "outputId": "7dda8960-6cea-4e9b-915a-9f7ad9304221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8420 - val_loss: 0.4703\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4815 - val_loss: 0.4247\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4519 - val_loss: 0.4052\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4429 - val_loss: 0.3975\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4368 - val_loss: 0.3991\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4340 - val_loss: 0.4031\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4043\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4267 - val_loss: 0.3929\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4258 - val_loss: 0.4040\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4237 - val_loss: 0.3886\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.3999\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4085\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.3922\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.3918\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.3886\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.3933\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.3907\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.3955\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.3935\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.3891\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4251\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  13.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7452 - val_loss: 0.4860\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4649 - val_loss: 0.4280\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4495 - val_loss: 0.5791\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4438 - val_loss: 0.4549\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4414 - val_loss: 0.5250\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4409 - val_loss: 0.5486\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4388 - val_loss: 0.5871\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4381 - val_loss: 0.4759\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.7523\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4369 - val_loss: 0.7478\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.8981\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4347 - val_loss: 0.8543\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4537\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   8.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 10.8724 - val_loss: 4.2476\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0257 - val_loss: 0.5794\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5263 - val_loss: 0.4357\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.4169\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4135\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4206\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4567 - val_loss: 0.4100\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4155\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4111\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4620 - val_loss: 0.4076\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4062\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4078\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4462 - val_loss: 0.4160\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4445 - val_loss: 0.4158\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4137\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4515 - val_loss: 0.4069\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4422 - val_loss: 0.4119\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4149\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.4081\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4141\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4100\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4473\n",
            "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  13.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1684 - val_loss: 6.2480\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6285 - val_loss: 5.2166\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.4474\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.3901\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.3736\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3803\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.3813\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.3961\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.3988\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3891\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.3870\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.3769\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3770\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.3848\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3768\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3560\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  10.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8828 - val_loss: 3.5738\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4887 - val_loss: 0.7767\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4267 - val_loss: 0.5515\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.5335\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3852 - val_loss: 0.5336\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.6750\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3678 - val_loss: 0.8462\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3610 - val_loss: 0.8724\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3554 - val_loss: 0.9645\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.7225\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.7257\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.7217\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.8443\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.7065\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3650\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  11.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0015 - val_loss: 2.9433\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5546 - val_loss: 4.2557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4854 - val_loss: 2.8526\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 1.6798\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4136 - val_loss: 0.4322\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3937 - val_loss: 0.4172\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.3769\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.3688\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.4032\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.3418\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4452\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.3454\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3526 - val_loss: 0.3395\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3503 - val_loss: 0.4354\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.3386\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4038\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3434 - val_loss: 0.3302\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3580\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.3546\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3460\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3244\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3257\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3441\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3301 - val_loss: 0.3377\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.3651\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3924\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3141\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3237 - val_loss: 0.3201\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3250 - val_loss: 0.4308\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3204\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3196 - val_loss: 0.3129\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3177 - val_loss: 0.4282\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3187 - val_loss: 0.3116\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3920\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3173 - val_loss: 0.4133\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3138 - val_loss: 0.6989\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3161 - val_loss: 0.7472\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 1.0275\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.4151\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.6727\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3126 - val_loss: 0.3498\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3079 - val_loss: 0.7570\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3116 - val_loss: 0.8347\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3180\n",
            "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  29.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.3936 - val_loss: 13.3699\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2098 - val_loss: 10.8972\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4360 - val_loss: 7.7330\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.0926 - val_loss: 5.0744\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9168 - val_loss: 3.2363\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8186 - val_loss: 2.1597\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7619 - val_loss: 1.4840\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7266 - val_loss: 1.1083\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7031 - val_loss: 0.8942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6858 - val_loss: 0.7687\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6720 - val_loss: 0.6947\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6602 - val_loss: 0.6524\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6498 - val_loss: 0.6234\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6401 - val_loss: 0.6061\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6312 - val_loss: 0.5933\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6227 - val_loss: 0.5819\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6147 - val_loss: 0.5733\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6070 - val_loss: 0.5650\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5997 - val_loss: 0.5578\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.5508\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5859 - val_loss: 0.5446\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5794 - val_loss: 0.5384\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5732 - val_loss: 0.5326\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5266\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5614 - val_loss: 0.5214\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5558 - val_loss: 0.5166\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5504 - val_loss: 0.5116\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5453 - val_loss: 0.5076\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 0.5035\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.4989\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.4946\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 0.4915\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.4883\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.4856\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5141 - val_loss: 0.4828\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.4789\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5066 - val_loss: 0.4780\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5030 - val_loss: 0.4742\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4995 - val_loss: 0.4729\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.4714\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.4686\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4897 - val_loss: 0.4666\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4867 - val_loss: 0.4646\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.4636\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4809 - val_loss: 0.4616\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4781 - val_loss: 0.4582\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.4581\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4729 - val_loss: 0.4573\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4704 - val_loss: 0.4560\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4680 - val_loss: 0.4544\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4656 - val_loss: 0.4525\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4527\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4611 - val_loss: 0.4522\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4589 - val_loss: 0.4509\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4568 - val_loss: 0.4509\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.4513\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4529 - val_loss: 0.4496\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4510 - val_loss: 0.4510\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4502\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4473 - val_loss: 0.4478\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4456 - val_loss: 0.4485\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4440 - val_loss: 0.4488\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4423 - val_loss: 0.4477\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4497\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4512\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4484\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4363 - val_loss: 0.4483\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4349 - val_loss: 0.4494\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4336 - val_loss: 0.4492\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 0.4476\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4309 - val_loss: 0.4481\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4296 - val_loss: 0.4503\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4486\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.4491\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4261 - val_loss: 0.4496\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4249 - val_loss: 0.4483\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4474\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4490\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4217 - val_loss: 0.4495\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4206 - val_loss: 0.4468\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4196 - val_loss: 0.4492\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4525\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.4504\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4525\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4158 - val_loss: 0.4495\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4148 - val_loss: 0.4548\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4140 - val_loss: 0.4512\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4132 - val_loss: 0.4481\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4123 - val_loss: 0.4472\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4114 - val_loss: 0.4506\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4209\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  55.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 3.4569 - val_loss: 7.5238\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.5656 - val_loss: 8.6120\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0607 - val_loss: 8.4896\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.8953 - val_loss: 7.7423\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8236 - val_loss: 6.8202\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7840 - val_loss: 5.9344\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7579 - val_loss: 5.1492\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7381 - val_loss: 4.4548\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7216 - val_loss: 3.9122\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7071 - val_loss: 3.4233\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6937 - val_loss: 2.9997\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6814 - val_loss: 2.6082\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6701 - val_loss: 2.2766\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6593 - val_loss: 1.9984\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6491 - val_loss: 1.7447\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6395 - val_loss: 1.5300\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6303 - val_loss: 1.3410\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6217 - val_loss: 1.1762\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 1.0345\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6055 - val_loss: 0.9174\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.8153\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.7363\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5839 - val_loss: 0.6696\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5774 - val_loss: 0.6187\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5711 - val_loss: 0.5778\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5652 - val_loss: 0.5491\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5594 - val_loss: 0.5299\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5540 - val_loss: 0.5199\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.5172\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.5206\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5312\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5447\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.5639\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5821\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5216 - val_loss: 0.6039\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5177 - val_loss: 0.6306\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.6564\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5104 - val_loss: 0.6820\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5069 - val_loss: 0.7087\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.5160\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  24.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 4.0974 - val_loss: 7.4460\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.1844 - val_loss: 5.2071\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4253 - val_loss: 2.9554\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0762 - val_loss: 1.7752\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9094 - val_loss: 1.1201\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8243 - val_loss: 0.8519\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7768 - val_loss: 0.7512\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7473 - val_loss: 0.7064\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7264 - val_loss: 0.6896\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7098 - val_loss: 0.6760\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6955 - val_loss: 0.6687\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6830 - val_loss: 0.6577\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6713 - val_loss: 0.6454\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6604 - val_loss: 0.6355\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6503 - val_loss: 0.6256\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6407 - val_loss: 0.6213\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6317 - val_loss: 0.6120\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6230 - val_loss: 0.6024\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6148 - val_loss: 0.5998\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6072 - val_loss: 0.5901\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5996 - val_loss: 0.5822\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5925 - val_loss: 0.5763\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5857 - val_loss: 0.5664\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5791 - val_loss: 0.5574\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5728 - val_loss: 0.5527\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5668 - val_loss: 0.5452\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5610 - val_loss: 0.5437\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 0.5366\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5501 - val_loss: 0.5322\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5450 - val_loss: 0.5264\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5399 - val_loss: 0.5234\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5352 - val_loss: 0.5175\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.5137\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5262 - val_loss: 0.5078\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5219 - val_loss: 0.5045\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5178 - val_loss: 0.4970\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5139 - val_loss: 0.4911\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 0.4887\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5064 - val_loss: 0.4847\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5029 - val_loss: 0.4815\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4994 - val_loss: 0.4776\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4962 - val_loss: 0.4736\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4930 - val_loss: 0.4706\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4901 - val_loss: 0.4673\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4871 - val_loss: 0.4655\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4843 - val_loss: 0.4625\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4816 - val_loss: 0.4576\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4789 - val_loss: 0.4554\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4764 - val_loss: 0.4525\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4740 - val_loss: 0.4495\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4716 - val_loss: 0.4468\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4693 - val_loss: 0.4446\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4670 - val_loss: 0.4420\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4649 - val_loss: 0.4394\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4628 - val_loss: 0.4373\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4607 - val_loss: 0.4349\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4588 - val_loss: 0.4330\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4569 - val_loss: 0.4311\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4550 - val_loss: 0.4291\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4532 - val_loss: 0.4277\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4515 - val_loss: 0.4257\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4498 - val_loss: 0.4241\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4482 - val_loss: 0.4224\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4466 - val_loss: 0.4208\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4451 - val_loss: 0.4193\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4436 - val_loss: 0.4180\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4164\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4151\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4395 - val_loss: 0.4141\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4124\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4369 - val_loss: 0.4112\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4357 - val_loss: 0.4101\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4345 - val_loss: 0.4088\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4334 - val_loss: 0.4081\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4323 - val_loss: 0.4073\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4312 - val_loss: 0.4070\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4301 - val_loss: 0.4056\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4291 - val_loss: 0.4040\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4281 - val_loss: 0.4034\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4033\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4262 - val_loss: 0.4019\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4253 - val_loss: 0.4008\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4244 - val_loss: 0.4002\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4236 - val_loss: 0.3996\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.3983\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4219 - val_loss: 0.3980\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.3981\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.3969\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.3978\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.3961\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4180 - val_loss: 0.3951\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4173 - val_loss: 0.3938\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4166 - val_loss: 0.3938\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.3935\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4152 - val_loss: 0.3934\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.3932\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.3939\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.3913\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.3916\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.3918\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4139\n",
            "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.0765 - val_loss: 1.3536\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7485 - val_loss: 0.7463\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6415 - val_loss: 0.5899\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5900 - val_loss: 0.5366\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5507 - val_loss: 0.5063\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5188 - val_loss: 0.4813\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4926 - val_loss: 0.4639\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4721 - val_loss: 0.4427\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4552 - val_loss: 0.4393\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4420 - val_loss: 0.4137\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4313 - val_loss: 0.4071\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4224 - val_loss: 0.3983\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4147 - val_loss: 0.3933\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.3972\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.3852\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.3830\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.3947\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.3713\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.3752\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3828 - val_loss: 0.3741\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.3782\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.3637\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.3723\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.3707\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4047\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.3839\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4167\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.3500\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.3792\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.3636\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3476\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3566 - val_loss: 0.3566\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3611\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.3414\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3474\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.3944\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.4401\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4721\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3722\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4019\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.3376\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.3377\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.3354\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.3737\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.3336\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3563\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.3547\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.3399\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.3304\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3850\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3393 - val_loss: 0.3430\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3363\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3386\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3294\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.3655\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3310\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.3730\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3375\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3340 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3403\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.3436\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3583\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.3306\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3679\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3298\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3272\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3299 - val_loss: 0.3565\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3295\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3282 - val_loss: 0.3440\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3550\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  46.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.8880 - val_loss: 3.4090\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7244 - val_loss: 1.6754\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6372 - val_loss: 0.9319\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5910 - val_loss: 0.6042\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5529 - val_loss: 0.5061\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5225 - val_loss: 0.5058\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4977 - val_loss: 0.5272\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4770 - val_loss: 0.5600\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4600 - val_loss: 0.5367\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.5221\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4356 - val_loss: 0.4878\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4264 - val_loss: 0.4531\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4187 - val_loss: 0.4182\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4124 - val_loss: 0.3877\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.3818\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4022\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4348\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3926 - val_loss: 0.4935\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.5340\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.5982\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.6541\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.7245\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.8045\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.8587\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.9089\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3884\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  17.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1014 - val_loss: 2.1643\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7146 - val_loss: 0.6141\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6063 - val_loss: 0.5601\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 0.5241\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.5017\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5034 - val_loss: 0.4749\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4814 - val_loss: 0.4558\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4633 - val_loss: 0.4297\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4483 - val_loss: 0.4464\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4189\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4438\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4250\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4009\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4403\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4014\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4247\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.3964\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.3974\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.4229\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4053\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3989\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3957\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.3864\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3774 - val_loss: 0.4022\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.3729\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3733 - val_loss: 0.3645\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4107\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3925\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4265\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.3879\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3789\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4080\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3631 - val_loss: 0.3873\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4232\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3718\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3593 - val_loss: 0.3663\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3555\n",
            "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  25.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2908 - val_loss: 297.3652\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.1716 - val_loss: 539.0366\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 6.2333 - val_loss: 3736.4507\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 11.9933 - val_loss: 12227.6982\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 54.7041 - val_loss: 61529.1016\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2281.0823 - val_loss: 268363.5625\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2760.9927 - val_loss: 1210517.0000\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 40359.3789 - val_loss: 5411004.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 83691.9375 - val_loss: 24506690.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1055625.6250 - val_loss: 119813024.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1860447.1250 - val_loss: 529731008.0000\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 1402365.2500\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   7.2s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0446 - val_loss: 15.8284\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5210 - val_loss: 22.4892\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 24.7894\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 22.4864\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5097 - val_loss: 21.9009\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5089 - val_loss: 21.2895\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5113 - val_loss: 19.9064\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5102 - val_loss: 22.5013\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 20.0987\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5087 - val_loss: 10.7128\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5083 - val_loss: 19.7319\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 24.3237\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5077 - val_loss: 25.9485\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 10.5277\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5078 - val_loss: 17.1916\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5064 - val_loss: 21.8347\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5058 - val_loss: 11.7743\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5101 - val_loss: 14.1555\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 20.9814\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 12.3621\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 25.9146\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 16.0461\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 19.4877\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5084 - val_loss: 12.1054\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.7813\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  14.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2328 - val_loss: 307.7496\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.9214 - val_loss: 76.3015\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3774 - val_loss: 795.2292\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 34.9847 - val_loss: 704.0450\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3027 - val_loss: 2668.0286\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 9.2431 - val_loss: 1446.2605\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.8034 - val_loss: 1540.5377\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 41.9016 - val_loss: 1396.7115\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 10.9509 - val_loss: 1334.0847\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.4803 - val_loss: 216.7268\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 13.8366 - val_loss: 125.2065\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6450 - val_loss: 2.2902\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7449 - val_loss: 790.5424\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 9.2398 - val_loss: 468.7424\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2300 - val_loss: 1073.9149\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 37.3800 - val_loss: 865.6385\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 8.9708 - val_loss: 1128.1501\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.8291 - val_loss: 499.5191\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 24.8681 - val_loss: 309.7941\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.6469 - val_loss: 354.6341\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.2841 - val_loss: 559.4488\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.5495 - val_loss: 393.8696\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.6226\n",
            "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=  13.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2632 - val_loss: 1.4543\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6364 - val_loss: 0.9557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.4628\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4783 - val_loss: 0.4214\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.3984\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.4056\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.3741\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3888 - val_loss: 0.3926\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.3832\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.3929\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.3570\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.3790\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.3840\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.3950\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.3751\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.3955\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3476 - val_loss: 0.3900\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.3905\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3420 - val_loss: 0.3944\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.3811\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3906\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3624\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  21.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0130 - val_loss: 0.5822\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5558 - val_loss: 0.4873\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4781 - val_loss: 0.4420\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4376 - val_loss: 0.4139\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4132\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4464\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.4717\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.5331\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 0.6951\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.6944\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.8506\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.7660\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.8731\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.9306\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.9345\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3685\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  21.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1090 - val_loss: 0.6796\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 0.4957\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4920 - val_loss: 0.4633\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4547 - val_loss: 0.4565\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4305 - val_loss: 0.4150\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4141 - val_loss: 0.4331\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.3887\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3936 - val_loss: 0.3785\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.4233\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.3652\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.4336\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3763\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.3632\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4460\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.3555\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.3947\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.3623\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.3774\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3806\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.3420\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.3452\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3446 - val_loss: 0.3273\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3279\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.4328\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.3426\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3366 - val_loss: 0.3228\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3342 - val_loss: 0.4407\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3357 - val_loss: 0.3301\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.4053\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3323 - val_loss: 0.3360\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3330\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3280 - val_loss: 0.3658\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3479\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3596\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3246 - val_loss: 0.3131\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3224 - val_loss: 0.3617\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.3386\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.5222\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.3333\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.4050\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3326\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3593\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3245\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3147 - val_loss: 0.3830\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3084\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3726\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3160\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3005\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3097 - val_loss: 0.4075\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3111 - val_loss: 0.2996\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3086 - val_loss: 0.4364\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3095 - val_loss: 0.3002\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3077 - val_loss: 0.2985\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3071 - val_loss: 0.2960\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3061 - val_loss: 0.2948\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.3314\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3056 - val_loss: 0.3077\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.2979\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3541\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3053 - val_loss: 0.3919\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3040 - val_loss: 0.3128\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3014 - val_loss: 0.3066\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.2950\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3006 - val_loss: 0.3041\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3008 - val_loss: 0.2944\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.3637\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2993 - val_loss: 0.3032\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.3324\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.2901\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2960 - val_loss: 0.3183\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2966 - val_loss: 0.2875\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2960 - val_loss: 0.2920\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2955 - val_loss: 0.2932\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.2857\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2945 - val_loss: 0.3148\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2927 - val_loss: 0.3570\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2964 - val_loss: 0.2876\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2937 - val_loss: 0.3106\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2933 - val_loss: 0.2915\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.2879\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.3139\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.3076\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.2900\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2906 - val_loss: 0.3418\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3057\n",
            "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time= 1.4min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1150 - val_loss: 29.5063\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0854 - val_loss: 33.7784\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9418 - val_loss: 4.0125\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6369 - val_loss: 0.5556\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5632 - val_loss: 0.5119\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5371 - val_loss: 0.4888\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5149 - val_loss: 0.4729\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4964 - val_loss: 0.4559\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4803 - val_loss: 0.4601\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4670 - val_loss: 0.4303\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4561 - val_loss: 0.4205\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4242\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4391 - val_loss: 0.4107\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4325 - val_loss: 0.4231\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4221\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4084\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4209\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4143 - val_loss: 0.4017\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4322\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4001\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4263\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4027 - val_loss: 0.4032\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4039\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.3764\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4241\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.3779\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3925 - val_loss: 0.4126\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.3967\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.4045\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.3748\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.3717\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.3676\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4054\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.3924\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3611\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4182\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.3539\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4403\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.3551\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4125\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.3665\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.3591\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.3570\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4125\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.3547\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.3779\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.3886\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3877\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  30.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.8463 - val_loss: 0.7805\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7088 - val_loss: 1.1550\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6196 - val_loss: 1.8115\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5692 - val_loss: 2.6113\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5319 - val_loss: 3.2626\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5046 - val_loss: 3.5247\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4841 - val_loss: 3.5926\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4679 - val_loss: 3.5562\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4551 - val_loss: 2.9541\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4459 - val_loss: 2.5606\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 2.1560\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4866\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   7.7s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.7445 - val_loss: 2.5834\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7268 - val_loss: 3.5564\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6419 - val_loss: 1.7895\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6134 - val_loss: 1.7436\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5564 - val_loss: 0.6344\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5303 - val_loss: 0.8713\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5070 - val_loss: 0.5604\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4919 - val_loss: 0.4695\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4759 - val_loss: 0.4942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4659 - val_loss: 0.4375\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4561 - val_loss: 0.4536\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4481 - val_loss: 0.4276\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 0.4084\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4354 - val_loss: 0.4897\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4300 - val_loss: 0.4018\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.5505\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4602\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4347\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.3835\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4115\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.3817\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.3737\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.3720\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4318\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3970 - val_loss: 0.4158\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3943 - val_loss: 0.3821\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3922 - val_loss: 0.4069\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3909 - val_loss: 0.4024\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.5904\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4027\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4216\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.3603\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4134\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.3633\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.3542\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.3568\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4216\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.5522\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.5648\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.6416\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.3847\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.5255\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.7023\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.7507\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.5608\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3745\n",
            "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  29.0s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.0682 - val_loss: 6.4183\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.7154 - val_loss: 16.7917\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5830 - val_loss: 4.7823\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4475 - val_loss: 8.6076\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4779 - val_loss: 1.8025\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.3655\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 0.3786\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.4054\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.3910\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3912\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3550\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.3612\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3650\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3625\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.3565\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3272 - val_loss: 0.3558\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3555\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3500\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3185 - val_loss: 0.3504\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3392\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3365\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3693\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3195\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3090 - val_loss: 0.3087\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3046 - val_loss: 0.3589\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3035 - val_loss: 0.3122\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3030 - val_loss: 0.3275\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3019 - val_loss: 0.3536\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2986 - val_loss: 0.3315\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2963 - val_loss: 0.2960\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2953 - val_loss: 0.3122\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2935 - val_loss: 0.2887\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2911 - val_loss: 0.3220\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2890 - val_loss: 0.3172\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2880 - val_loss: 0.2943\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2869 - val_loss: 0.3723\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2858 - val_loss: 0.3260\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.3555\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2838 - val_loss: 0.2923\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2823 - val_loss: 0.3324\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2808 - val_loss: 0.2885\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2800 - val_loss: 0.2909\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2792 - val_loss: 0.2860\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2768 - val_loss: 0.3188\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2767 - val_loss: 0.3108\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2756 - val_loss: 0.3249\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2739 - val_loss: 0.2890\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2737 - val_loss: 0.2840\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2713 - val_loss: 0.2777\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2714 - val_loss: 0.3328\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2700 - val_loss: 0.3179\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2687 - val_loss: 0.3177\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2684 - val_loss: 0.2842\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2667 - val_loss: 0.2830\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2653 - val_loss: 0.2988\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2660 - val_loss: 0.2723\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2639 - val_loss: 0.3335\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2645 - val_loss: 0.2753\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2633 - val_loss: 0.2905\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2614 - val_loss: 0.2812\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2627 - val_loss: 0.3755\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2613 - val_loss: 0.2795\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2600 - val_loss: 0.3285\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2603 - val_loss: 0.2762\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2574 - val_loss: 0.3070\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2584 - val_loss: 0.3185\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3105\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  45.4s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8717 - val_loss: 0.7369\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 0.4431\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.3919\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.3834\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.3951\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4650\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.6408\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.7273\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.9104\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.6969\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.6999\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.7835\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.8539\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3277 - val_loss: 0.8282\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3525\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  10.3s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9177 - val_loss: 0.9196\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4767 - val_loss: 2.1030\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4329 - val_loss: 3.5546\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4408 - val_loss: 1.5870\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4229\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.3736\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3634 - val_loss: 0.3347\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.3389\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.3714\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.3271\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 0.3873\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3337\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3220\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3691\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3202\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3290 - val_loss: 0.3598\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3268 - val_loss: 0.3241\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3532\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3222 - val_loss: 0.3357\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3616\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3152\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3175\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3129 - val_loss: 0.3580\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3041\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3096 - val_loss: 0.3216\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3067 - val_loss: 0.3245\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3053 - val_loss: 0.3125\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3044 - val_loss: 0.3490\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3862\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3183\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2996 - val_loss: 0.3122\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2974 - val_loss: 0.3014\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2976 - val_loss: 0.3222\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2959 - val_loss: 0.3020\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2932 - val_loss: 0.2965\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2908 - val_loss: 0.4448\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2910 - val_loss: 0.3683\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2941 - val_loss: 0.4166\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2913 - val_loss: 0.2964\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2919 - val_loss: 0.3617\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2875 - val_loss: 0.3154\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2859 - val_loss: 0.3138\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2860 - val_loss: 0.2842\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2830 - val_loss: 0.3241\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.2951\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.3328\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2803 - val_loss: 0.2820\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2800 - val_loss: 0.2838\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2797 - val_loss: 0.3641\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2781 - val_loss: 0.2970\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2772 - val_loss: 0.3488\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2765 - val_loss: 0.2949\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2758 - val_loss: 0.2940\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2754 - val_loss: 0.2973\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2739 - val_loss: 0.2806\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2746 - val_loss: 0.3015\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2733 - val_loss: 0.3550\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2752 - val_loss: 0.2928\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2720 - val_loss: 0.3158\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2709 - val_loss: 0.2777\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2694 - val_loss: 0.3425\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2696 - val_loss: 0.2753\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2688 - val_loss: 0.3171\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2686 - val_loss: 0.2864\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2689 - val_loss: 0.2885\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2660 - val_loss: 0.2939\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2654 - val_loss: 0.2901\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2720 - val_loss: 0.2933\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2652 - val_loss: 0.2779\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2630 - val_loss: 0.2849\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2643 - val_loss: 0.2742\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2641 - val_loss: 0.2750\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2637 - val_loss: 0.2925\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2631 - val_loss: 0.2811\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2625 - val_loss: 0.2931\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.3316\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2619 - val_loss: 0.2795\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2611 - val_loss: 0.4124\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2609 - val_loss: 0.2784\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2583 - val_loss: 0.2716\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2587 - val_loss: 0.2975\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2570 - val_loss: 0.2786\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2579 - val_loss: 0.3338\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2599 - val_loss: 0.2742\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2568 - val_loss: 0.2930\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2561 - val_loss: 0.2810\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2567 - val_loss: 0.3121\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2540 - val_loss: 0.2711\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2541 - val_loss: 0.2792\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2549 - val_loss: 0.3115\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2564 - val_loss: 0.2751\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2544 - val_loss: 0.2695\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2531 - val_loss: 0.2903\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2523 - val_loss: 0.2842\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2519 - val_loss: 0.3035\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2502 - val_loss: 0.3096\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2538 - val_loss: 0.2928\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2530 - val_loss: 0.3358\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2514 - val_loss: 0.2702\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2515 - val_loss: 0.2945\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.2939\n",
            "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time= 1.2min\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.9615 - val_loss: 10.9250\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5921 - val_loss: 3.3912\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4539 - val_loss: 0.4039\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.3692\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.3555\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.3875\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3633\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.3991\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3797\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3704\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3310\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.3509\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3269 - val_loss: 0.3795\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3261 - val_loss: 0.3311\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3491\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3473\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3172 - val_loss: 0.3259\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3418\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3123 - val_loss: 0.3327\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3108 - val_loss: 0.3266\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3087 - val_loss: 0.3732\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3082 - val_loss: 0.3087\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3047 - val_loss: 0.3960\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3903\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3041 - val_loss: 0.3345\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.3226\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2983 - val_loss: 0.3266\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2973 - val_loss: 0.4213\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2953 - val_loss: 0.3040\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2916 - val_loss: 0.2987\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2911 - val_loss: 0.3067\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2899 - val_loss: 0.2938\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2881 - val_loss: 0.3369\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2851 - val_loss: 0.3338\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2843 - val_loss: 0.2913\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2837 - val_loss: 0.3635\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2827 - val_loss: 0.3303\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2835 - val_loss: 0.3682\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2811 - val_loss: 0.2938\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2792 - val_loss: 0.3416\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2781 - val_loss: 0.2859\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2768 - val_loss: 0.3175\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2761 - val_loss: 0.2921\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2742 - val_loss: 0.3232\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2746 - val_loss: 0.2796\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2734 - val_loss: 0.3144\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2715 - val_loss: 0.3168\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2708 - val_loss: 0.3099\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.2804\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.3781\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2686 - val_loss: 0.3156\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2661 - val_loss: 0.3562\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2669 - val_loss: 0.2884\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2645 - val_loss: 0.3015\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2634 - val_loss: 0.2914\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3096\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  38.1s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8381 - val_loss: 0.6551\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4570 - val_loss: 0.4129\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.6096\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.6534\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.6227\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.8403\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 1.0599\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 1.1357\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3456 - val_loss: 1.2306\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.8012\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.8288\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.7655\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3590\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   8.9s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.8683 - val_loss: 2.2007\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5072 - val_loss: 3.3028\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4486 - val_loss: 0.9130\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.5328\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.3609\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.4151\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3580\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.3516\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3983\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3511 - val_loss: 0.3323\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4233\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3420 - val_loss: 0.3284\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3469\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3337 - val_loss: 0.4037\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3269\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3290 - val_loss: 0.3776\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3215\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3228 - val_loss: 0.3289\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3861\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3191 - val_loss: 0.3255\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3179 - val_loss: 0.3954\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3162\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3483\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3134 - val_loss: 0.3197\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3071\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3075 - val_loss: 0.3091\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.4026\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3063 - val_loss: 0.3323\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.3773\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3028 - val_loss: 0.3524\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3003 - val_loss: 0.3063\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.4479\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2988 - val_loss: 0.3099\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2943 - val_loss: 0.3688\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2973 - val_loss: 0.3005\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2925 - val_loss: 0.3865\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.3046\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.3832\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2895 - val_loss: 0.2934\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2879 - val_loss: 0.3557\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2861 - val_loss: 0.3303\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2850 - val_loss: 0.4287\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.3025\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.3580\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2841 - val_loss: 0.2973\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2807 - val_loss: 0.3387\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2798 - val_loss: 0.2834\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2794 - val_loss: 0.2920\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2779 - val_loss: 0.4260\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2774 - val_loss: 0.3424\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2755 - val_loss: 0.4973\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2757 - val_loss: 0.3619\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2769 - val_loss: 0.3058\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2756 - val_loss: 0.3160\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2737 - val_loss: 0.2864\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2723 - val_loss: 0.4389\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2731 - val_loss: 0.2829\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2722 - val_loss: 0.3853\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2696 - val_loss: 0.3173\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2702 - val_loss: 0.2824\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2682 - val_loss: 0.3398\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2670 - val_loss: 0.2955\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2678 - val_loss: 0.3129\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2689 - val_loss: 0.3233\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2670 - val_loss: 0.2832\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2639 - val_loss: 0.3293\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2636 - val_loss: 0.2926\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2639 - val_loss: 0.3411\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2626 - val_loss: 0.2810\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2599 - val_loss: 0.4058\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2644 - val_loss: 0.3018\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2640 - val_loss: 0.3223\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2621 - val_loss: 0.2886\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2616 - val_loss: 0.2853\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2610 - val_loss: 0.3097\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2563 - val_loss: 0.3753\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2592 - val_loss: 0.2914\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2569 - val_loss: 0.2833\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2571 - val_loss: 0.3132\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.2846\n",
            "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  54.8s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.2259 - val_loss: 0.5753\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5658 - val_loss: 8.9879\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5484 - val_loss: 11.0986\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5602 - val_loss: 1.1306\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4336 - val_loss: 0.5258\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4499\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4056\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.3998\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.3957\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.3903\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.3688\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3651\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.3709\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3817\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.3623\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3671\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3672\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.3606\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3552\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3536\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3416 - val_loss: 0.3519\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3388 - val_loss: 0.3474\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.3510\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3304\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3686\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3246\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3336 - val_loss: 0.3387\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3367\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3279 - val_loss: 0.3389\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3276 - val_loss: 0.3209\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3227\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3150\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3511\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3222 - val_loss: 0.3161\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3141\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3191 - val_loss: 0.3843\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.3600\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3544\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3159 - val_loss: 0.3168\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3405\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3163\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3164\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3143\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3418\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3144 - val_loss: 0.3057\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3302\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3330\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3175\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3073 - val_loss: 0.3019\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3068 - val_loss: 0.3649\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3061 - val_loss: 0.3269\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3047 - val_loss: 0.3405\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3068\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3089\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3030 - val_loss: 0.3346\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3041 - val_loss: 0.3000\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3014 - val_loss: 0.3707\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3036 - val_loss: 0.3165\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.2981\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2991 - val_loss: 0.3177\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2997 - val_loss: 0.3231\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2982 - val_loss: 0.3422\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2984 - val_loss: 0.3082\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2962 - val_loss: 0.4176\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2971 - val_loss: 0.3030\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3343\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2953 - val_loss: 0.2985\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2943 - val_loss: 0.3713\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2958 - val_loss: 0.2969\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2947 - val_loss: 0.3563\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.2941\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.3500\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.2962\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2903 - val_loss: 0.4277\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2917 - val_loss: 0.2926\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2892 - val_loss: 0.3673\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2926 - val_loss: 0.3217\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2894 - val_loss: 0.5634\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2941 - val_loss: 0.3334\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2879 - val_loss: 0.5032\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2882 - val_loss: 0.3119\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2863 - val_loss: 0.6628\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2921 - val_loss: 0.6841\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2900 - val_loss: 0.8619\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2912 - val_loss: 0.3784\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3198\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  57.5s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1975 - val_loss: 0.8898\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5319 - val_loss: 0.5270\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4524 - val_loss: 0.4844\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4199 - val_loss: 0.4250\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.3735\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.3859\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.4576\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4928\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.6246\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.5255\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.5956\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.6364\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.7456\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.7136\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.6905\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3615\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  10.6s\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.1315 - val_loss: 2.8528\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.6016 - val_loss: 2.3412\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5108 - val_loss: 0.9015\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 0.8313\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4291 - val_loss: 0.5217\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4956\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.3745\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.4012\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4169\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3843\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.6122\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.3579\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3497\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.5161\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4273\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.5739\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.4975\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4886\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.3371\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4118\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.3310\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.3289\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.3287\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 0.5224\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.7689\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.8909\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.4864\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.6169\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3470\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.5750\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3332 - val_loss: 0.3685\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3308 - val_loss: 0.7292\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3932\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3362\n",
            "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  22.5s\n",
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.8571 - val_loss: 6.5088\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5640 - val_loss: 7.3062\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4741 - val_loss: 0.5231\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.3947\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3606 - val_loss: 0.5391\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.3491\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.3398\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.3290\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3381 - val_loss: 0.4460\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.9023\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.9399\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3346 - val_loss: 0.3403\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.3268\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3238 - val_loss: 0.3160\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3209 - val_loss: 0.3049\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3179 - val_loss: 0.4244\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3026\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3336\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 0.4325\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3407\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3071 - val_loss: 0.6759\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3085 - val_loss: 1.1320\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3111 - val_loss: 0.6132\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3048 - val_loss: 0.2987\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3012 - val_loss: 0.3811\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2995 - val_loss: 0.2994\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.3678\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.2900\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2942 - val_loss: 0.3994\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2963 - val_loss: 0.3507\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.4075\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2900 - val_loss: 0.2893\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2874 - val_loss: 0.2929\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2859 - val_loss: 0.3547\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2846 - val_loss: 0.3140\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2834 - val_loss: 0.3900\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2817 - val_loss: 0.3061\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2824 - val_loss: 0.3524\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2806 - val_loss: 0.2849\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2799 - val_loss: 0.3960\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2804 - val_loss: 0.2764\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2753 - val_loss: 0.3827\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2761 - val_loss: 0.3170\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2740 - val_loss: 0.2777\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2742 - val_loss: 0.3093\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2742 - val_loss: 0.2817\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2724 - val_loss: 0.3744\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2719 - val_loss: 0.2851\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2697 - val_loss: 0.3586\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2707 - val_loss: 0.2731\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2687 - val_loss: 0.2777\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2682 - val_loss: 0.4556\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2683 - val_loss: 0.7225\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2693 - val_loss: 1.1079\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2719 - val_loss: 0.7613\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2707 - val_loss: 0.8934\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2689 - val_loss: 0.3215\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2667 - val_loss: 0.3987\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2648 - val_loss: 0.2679\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2616 - val_loss: 0.3196\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2631 - val_loss: 0.3023\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2629 - val_loss: 0.2740\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2652 - val_loss: 0.3065\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2606 - val_loss: 0.2730\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2597 - val_loss: 0.3227\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2603 - val_loss: 0.2671\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2574 - val_loss: 0.3146\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2590 - val_loss: 0.2752\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2571 - val_loss: 0.3387\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2573 - val_loss: 0.2889\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2560 - val_loss: 0.2777\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2567 - val_loss: 0.2791\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2571 - val_loss: 0.3839\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2551 - val_loss: 0.3094\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2546 - val_loss: 0.3533\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.2540 - val_loss: 0.3028\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f2da3cac890>,\n",
              "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
              "                                                          0.02390836445593178,\n",
              "                                                          0.008731907739399206,\n",
              "                                                          0.004725396149933917,\n",
              "                                                          0.0006154014789262348,\n",
              "                                                          0.0006153331256530192,\n",
              "                                                          0.0003920021771415983,\n",
              "                                                          0.01619845322936229,\n",
              "                                                          0.004779156784872302,\n",
              "                                                          0.007821074275112298,...\n",
              "                                                          0.005021425736625637,\n",
              "                                                          0.0005703073595961105,\n",
              "                                                          0.001151888789941251,\n",
              "                                                          0.001621231156394198,\n",
              "                                                          0.0024505367684280487,\n",
              "                                                          0.011155092541719619,\n",
              "                                                          0.0007524347058135697,\n",
              "                                                          0.0032032448128444043,\n",
              "                                                          0.004591455636549438,\n",
              "                                                          0.0003715541189658278, ...],\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14, 15,\n",
              "                                                      16, 17, 18, 19, 20, 21,\n",
              "                                                      22, 23, 24, 25, 26, 27,\n",
              "                                                      28, 29, 30, ...]},\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4ZRgWyxq-iO",
        "outputId": "aa3b64dc-8abd-47f1-ff37-b42aa65ed4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neurons': 80, 'n_hidden': 3, 'learning_rate': 0.0059640580092043885}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMJNshNPKbaS",
        "outputId": "62343591-1c56-4940-fae0-82619ab0dc4e"
      },
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_neurons': 74, 'n_hidden': 3, 'learning_rate': 0.005803602934201024}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcHT7W_zKbaS",
        "outputId": "70894fc9-8687-44bc-8380-42050343bae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3177357614040375"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wYZAWg0KbaS",
        "outputId": "8ce6e10d-82a5-4a3c-cb1a-4bd351affc25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnd_search_cv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.wrappers.scikit_learn.KerasRegressor at 0x7f2d9d9137d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUovM1pwKbaT",
        "outputId": "fb0297df-283b-4ffb-c5a0-8d21b265582e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnd_search_cv.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.2788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2787829637527466"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXOvffS0KbaT",
        "outputId": "e7a2e29c-2963-42b5-d606-0e0c1babdb5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = rnd_search_cv.best_estimator_.model\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f2d9d98cb10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OlJtmGXEKbaT",
        "outputId": "2541c7ff-b4db-41d6-a82b-3cccadc50147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.2788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2787829637527466"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnONki5gj0w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# <font color='#f78fb3'> **2 Classification**<br> </font> "
      ],
      "metadata": {
        "id": "3cYH7AvzkSTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#f78fb3'> <font color='#f9ca24'>**2.1 Fashion MNISTS**<br> </font>  "
      ],
      "metadata": {
        "id": "zqX9wsewkSTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Prepare data**</font>"
      ],
      "metadata": {
        "id": "Mxa4Y94ekSTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjJ-UWS1XMqa",
        "outputId": "a926b4ac-7023-48c0-fac2-918e4ba938d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7d03a8-02b9-429f-8896-441ec685be29",
        "id": "vG9JOM5fkSTO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "8wwO-cx0kSTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Construction Phase**</font>"
      ],
      "metadata": {
        "id": "o5b3v29HkSTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(300, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tr4jILzXhBO",
        "outputId": "1b5528d2-51b8-40f3-801b-680028e76a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "36283bb6-0da5-4bdd-8a73-5c7a863c3e92",
        "id": "i5soZNUckSTQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = model.layers[1]\n",
        "weights, biases = hidden1.get_weights()\n",
        "weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IoS4Y8yYTR9",
        "outputId": "f672aaea-8b83-4ea0-cd73-5b26cf414ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Execution Phase**</font>"
      ],
      "metadata": {
        "id": "lXZ9fAiikSTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',  # keras.losses.sparse_categorical_crossentropy\n",
        "              optimizer='sgd',   # keras.optimizers.SGD()\n",
        "              metrics='accuracy')  # keras.metrics.sparse_category_accuracy\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518e07f7-2830-44f6-d2f9-5123e8ccffca",
        "id": "FPLuBcp6kSTS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 5s 2ms/step - loss: 0.7237 - accuracy: 0.7644 - val_loss: 0.5207 - val_accuracy: 0.8234\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4843 - accuracy: 0.8318 - val_loss: 0.4345 - val_accuracy: 0.8538\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4393 - accuracy: 0.8455 - val_loss: 0.5316 - val_accuracy: 0.7990\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4126 - accuracy: 0.8564 - val_loss: 0.3915 - val_accuracy: 0.8650\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3940 - accuracy: 0.8618 - val_loss: 0.3749 - val_accuracy: 0.8684\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3752 - accuracy: 0.8674 - val_loss: 0.3711 - val_accuracy: 0.8716\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3634 - accuracy: 0.8712 - val_loss: 0.3614 - val_accuracy: 0.8716\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3518 - accuracy: 0.8749 - val_loss: 0.3845 - val_accuracy: 0.8620\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3415 - accuracy: 0.8789 - val_loss: 0.3582 - val_accuracy: 0.8704\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3322 - accuracy: 0.8819 - val_loss: 0.3439 - val_accuracy: 0.8768\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3242 - accuracy: 0.8832 - val_loss: 0.3435 - val_accuracy: 0.8786\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3149 - accuracy: 0.8866 - val_loss: 0.3309 - val_accuracy: 0.8810\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3081 - accuracy: 0.8889 - val_loss: 0.3263 - val_accuracy: 0.8892\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3023 - accuracy: 0.8911 - val_loss: 0.3389 - val_accuracy: 0.8786\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2948 - accuracy: 0.8938 - val_loss: 0.3210 - val_accuracy: 0.8852\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2891 - accuracy: 0.8974 - val_loss: 0.3092 - val_accuracy: 0.8914\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2839 - accuracy: 0.8978 - val_loss: 0.3551 - val_accuracy: 0.8738\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2779 - accuracy: 0.9000 - val_loss: 0.3142 - val_accuracy: 0.8906\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2728 - accuracy: 0.9020 - val_loss: 0.3111 - val_accuracy: 0.8894\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2675 - accuracy: 0.9034 - val_loss: 0.3266 - val_accuracy: 0.8822\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2625 - accuracy: 0.9052 - val_loss: 0.3041 - val_accuracy: 0.8932\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2577 - accuracy: 0.9074 - val_loss: 0.2974 - val_accuracy: 0.8960\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2535 - accuracy: 0.9082 - val_loss: 0.2976 - val_accuracy: 0.8926\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2486 - accuracy: 0.9106 - val_loss: 0.3086 - val_accuracy: 0.8872\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2444 - accuracy: 0.9122 - val_loss: 0.2968 - val_accuracy: 0.8954\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2407 - accuracy: 0.9132 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2364 - accuracy: 0.9153 - val_loss: 0.3024 - val_accuracy: 0.8950\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2329 - accuracy: 0.9166 - val_loss: 0.3006 - val_accuracy: 0.8930\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2284 - accuracy: 0.9183 - val_loss: 0.3048 - val_accuracy: 0.8898\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2252 - accuracy: 0.9190 - val_loss: 0.3029 - val_accuracy: 0.8940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.params)\n",
        "print(history.epoch)\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d567f4f-e3de-4687-ddd9-01b3cc81b3db",
        "id": "IwUbbYYUkSTS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': 1, 'epochs': 30, 'steps': 1719}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Performance Evaluation**</font>"
      ],
      "metadata": {
        "id": "UPN6NQ1zkSTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "dc7e2529-a7ae-4f48-818c-11099bc7fb0a",
        "id": "cou6fGXwkSTT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025a7ad8-67a3-47e4-af3a-26e083c2add1",
        "id": "HTWPqKRakSTU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3370753824710846, 0.8844000101089478]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608754ce-5286-4e72-f119-b4c6615bb77c",
        "id": "vgIjy1UtkSTU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96],\n",
              "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Prediction**</font>"
      ],
      "metadata": {
        "id": "aWci7wkFkSTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred = model.predict_classes(X_new) # deprecated\n",
        "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341aa98e-1d88-40ee-e853-a90bef816e17",
        "id": "ZpUG9VF3kSTV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#f78fb3'> <font color='#f9ca24'>**2.2 MNISTS**<br> </font>  "
      ],
      "metadata": {
        "id": "nwNdIUkpERHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Dataset**</font>"
      ],
      "metadata": {
        "id": "jww4dOMIEVIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "X_train_full.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GsfbpnrEYZA",
        "outputId": "6df971ab-bd8e-439c-eaf7-6e9ee1384116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "dfEulf3EEgA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='lightgreen'>**Searching optimal learning rate**</font>\n",
        "<font color='#3dc1d3'> \n",
        "+ Growing the learning rate exponentially\n",
        "+ Plotting the loss, finding the point where the loss shoots up\n",
        "+ Save checkpoints, use early stopping\n",
        "+ Plot learning curves using TensorBoard </font>"
      ],
      "metadata": {
        "id": "4qPLtOYQ69KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "    self.rates = []\n",
        "    self.losses = []\n",
        "  def on_batch_end(self, batch, logs):\n",
        "    self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "    self.losses.append(logs[\"loss\"])\n",
        "    K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)"
      ],
      "metadata": {
        "id": "l1FsU2Dc9AJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Flatten(input_shape=[28,28]),\n",
        "  keras.layers.Dense(300, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation='relu'),\n",
        "  keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])\n",
        "expon_lr = ExponentialLearningRate(factor=1.005)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[expon_lr])"
      ],
      "metadata": {
        "id": "gqupwtUDBZ5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b70e50-e66d-43cd-fcfc-1e86b949f2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 6s 3ms/step - loss: nan - accuracy: 0.5773 - val_loss: nan - val_accuracy: 0.0958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(expon_lr.rates, expon_lr.losses)\n",
        "plt.gca().set_xscale('log')\n",
        "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
        "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "8ok7qZdslkUF",
        "outputId": "0d6c1bd2-5d27-46ad-8684-4d8818be8bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWkOnts-KbaZ"
      },
      "source": [
        "The loss starts shooting back up violently when the learning rate goes over 6e-1, so let's try using half of that, at 3e-1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWVUuVtuKbaZ"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXHJ7KDvKbaa"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-4-oVrFKbaa"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=3e-1),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1AHxKz3Kbaa",
        "outputId": "d4c0268c-acce-4a6c-80f1-5f5ee1fdbb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "run_index = 1 # increment this at every run\n",
        "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
        "run_logdir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_mnist_logs/run_001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRKJ3n_aKbaa",
        "outputId": "daaeee6c-dad0-4697-9e5f-1924657032d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2363 - accuracy: 0.9263 - val_loss: 0.0975 - val_accuracy: 0.9712\n",
            "Epoch 2/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9699 - val_loss: 0.1055 - val_accuracy: 0.9708\n",
            "Epoch 3/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0673 - accuracy: 0.9783 - val_loss: 0.0779 - val_accuracy: 0.9766\n",
            "Epoch 4/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0474 - accuracy: 0.9848 - val_loss: 0.0721 - val_accuracy: 0.9796\n",
            "Epoch 5/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0778 - val_accuracy: 0.9800\n",
            "Epoch 6/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.0741 - val_accuracy: 0.9826\n",
            "Epoch 7/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0757 - val_accuracy: 0.9820\n",
            "Epoch 8/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.1483 - val_accuracy: 0.9632\n",
            "Epoch 9/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0828 - val_accuracy: 0.9826\n",
            "Epoch 10/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.0911 - val_accuracy: 0.9818\n",
            "Epoch 11/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0853 - val_accuracy: 0.9824\n",
            "Epoch 12/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1291 - val_accuracy: 0.9764\n",
            "Epoch 13/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0897 - val_accuracy: 0.9828\n",
            "Epoch 14/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0840 - val_accuracy: 0.9838\n",
            "Epoch 15/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0935 - val_accuracy: 0.9838\n",
            "Epoch 16/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.1004 - val_accuracy: 0.9832\n",
            "Epoch 17/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0944 - val_accuracy: 0.9822\n",
            "Epoch 18/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0971 - val_accuracy: 0.9828\n",
            "Epoch 19/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0930 - val_accuracy: 0.9846\n",
            "Epoch 20/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 2.4558e-04 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9852\n",
            "Epoch 21/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 9.0046e-05 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9856\n",
            "Epoch 22/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 6.7954e-05 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9854\n",
            "Epoch 23/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 5.7146e-05 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9852\n",
            "Epoch 24/100\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 4.9728e-05 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpzvKr79Kbab",
        "outputId": "8c4fc5d8-3278-4973-8799-51adbbd99b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0771 - accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07713202387094498, 0.9765999913215637]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po4G5sVKbab"
      },
      "source": [
        "We got over 98% accuracy. Finally, let's look at the learning curves using TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBTjyFUEKbab"
      },
      "source": [
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir=./my_mnist_logs --port=6008"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "xJW_lgyFuc59"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzM8VSt8P6bg"
      },
      "source": [
        "### 6.5. Example Three: Adding in DropOut Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYHxLPlZP6bg",
        "outputId": "3ddb2c98-1c6a-408a-8c39-c316f3c66c2d"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=30,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=15,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=600,\n",
        "          validation_data=(X_test, y_test), verbose=1,\n",
        "          callbacks=[early_stop]\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "14/14 [==============================] - 1s 11ms/step - loss: 0.6949 - val_loss: 0.6889\n",
            "Epoch 2/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6858 - val_loss: 0.6750\n",
            "Epoch 3/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.6629\n",
            "Epoch 4/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6481\n",
            "Epoch 5/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6491 - val_loss: 0.6333\n",
            "Epoch 6/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.6277 - val_loss: 0.6165\n",
            "Epoch 7/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6183 - val_loss: 0.5969\n",
            "Epoch 8/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5897 - val_loss: 0.5719\n",
            "Epoch 9/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5783 - val_loss: 0.5462\n",
            "Epoch 10/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5544 - val_loss: 0.5114\n",
            "Epoch 11/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5208 - val_loss: 0.4717\n",
            "Epoch 12/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5037 - val_loss: 0.4327\n",
            "Epoch 13/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4537 - val_loss: 0.3970\n",
            "Epoch 14/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4326 - val_loss: 0.3584\n",
            "Epoch 15/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4336 - val_loss: 0.3367\n",
            "Epoch 16/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3781 - val_loss: 0.3034\n",
            "Epoch 17/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3510 - val_loss: 0.2734\n",
            "Epoch 18/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3575 - val_loss: 0.2571\n",
            "Epoch 19/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3323 - val_loss: 0.2461\n",
            "Epoch 20/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3347 - val_loss: 0.2261\n",
            "Epoch 21/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3039 - val_loss: 0.2151\n",
            "Epoch 22/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2831 - val_loss: 0.2090\n",
            "Epoch 23/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 0.1968\n",
            "Epoch 24/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2627 - val_loss: 0.1883\n",
            "Epoch 25/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2591 - val_loss: 0.1879\n",
            "Epoch 26/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2677 - val_loss: 0.1730\n",
            "Epoch 27/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2550 - val_loss: 0.1733\n",
            "Epoch 28/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2447 - val_loss: 0.1730\n",
            "Epoch 29/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2346 - val_loss: 0.1617\n",
            "Epoch 30/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2613 - val_loss: 0.1770\n",
            "Epoch 31/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2447 - val_loss: 0.1759\n",
            "Epoch 32/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2332 - val_loss: 0.1540\n",
            "Epoch 33/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2147 - val_loss: 0.1532\n",
            "Epoch 34/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1981 - val_loss: 0.1460\n",
            "Epoch 35/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.2020 - val_loss: 0.1460\n",
            "Epoch 36/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1917 - val_loss: 0.1441\n",
            "Epoch 37/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2243 - val_loss: 0.1401\n",
            "Epoch 38/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1918 - val_loss: 0.1339\n",
            "Epoch 39/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1929 - val_loss: 0.1341\n",
            "Epoch 40/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2021 - val_loss: 0.1307\n",
            "Epoch 41/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1707 - val_loss: 0.1296\n",
            "Epoch 42/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1907 - val_loss: 0.1323\n",
            "Epoch 43/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1708 - val_loss: 0.1255\n",
            "Epoch 44/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1724 - val_loss: 0.1268\n",
            "Epoch 45/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1739 - val_loss: 0.1216\n",
            "Epoch 46/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.1257\n",
            "Epoch 47/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1698 - val_loss: 0.1233\n",
            "Epoch 48/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1708 - val_loss: 0.1323\n",
            "Epoch 49/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 0.1215\n",
            "Epoch 50/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.1209\n",
            "Epoch 51/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1610 - val_loss: 0.1212\n",
            "Epoch 52/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1544 - val_loss: 0.1190\n",
            "Epoch 53/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1557 - val_loss: 0.1220\n",
            "Epoch 54/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1535 - val_loss: 0.1178\n",
            "Epoch 55/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1353 - val_loss: 0.1161\n",
            "Epoch 56/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1667 - val_loss: 0.1123\n",
            "Epoch 57/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1430 - val_loss: 0.1304\n",
            "Epoch 58/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1141 - val_loss: 0.1122\n",
            "Epoch 59/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1267 - val_loss: 0.1154\n",
            "Epoch 60/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1449 - val_loss: 0.1170\n",
            "Epoch 61/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1455 - val_loss: 0.1136\n",
            "Epoch 62/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1372 - val_loss: 0.1175\n",
            "Epoch 63/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1617 - val_loss: 0.1348\n",
            "Epoch 64/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1231 - val_loss: 0.1131\n",
            "Epoch 65/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1321 - val_loss: 0.1193\n",
            "Epoch 66/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1375 - val_loss: 0.1159\n",
            "Epoch 67/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1401 - val_loss: 0.1119\n",
            "Epoch 68/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1240 - val_loss: 0.1174\n",
            "Epoch 69/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1346 - val_loss: 0.1179\n",
            "Epoch 70/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.1166\n",
            "Epoch 71/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1108\n",
            "Epoch 72/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1371 - val_loss: 0.1221\n",
            "Epoch 73/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1445 - val_loss: 0.1203\n",
            "Epoch 74/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1253 - val_loss: 0.1123\n",
            "Epoch 75/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1067 - val_loss: 0.1174\n",
            "Epoch 76/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1306 - val_loss: 0.1176\n",
            "Epoch 77/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1147 - val_loss: 0.1143\n",
            "Epoch 78/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1298 - val_loss: 0.1185\n",
            "Epoch 79/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1052 - val_loss: 0.1147\n",
            "Epoch 80/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1129 - val_loss: 0.1127\n",
            "Epoch 81/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1157\n",
            "Epoch 82/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1146 - val_loss: 0.1351\n",
            "Epoch 83/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1115 - val_loss: 0.1136\n",
            "Epoch 84/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1328 - val_loss: 0.1199\n",
            "Epoch 85/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1034 - val_loss: 0.1147\n",
            "Epoch 86/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0951 - val_loss: 0.1216\n",
            "Epoch 87/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1051 - val_loss: 0.1148\n",
            "Epoch 88/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.1227\n",
            "Epoch 89/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.1169\n",
            "Epoch 90/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1119 - val_loss: 0.1129\n",
            "Epoch 91/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1167 - val_loss: 0.1246\n",
            "Epoch 92/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1382 - val_loss: 0.1345\n",
            "Epoch 93/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.1104\n",
            "Epoch 94/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1170 - val_loss: 0.1124\n",
            "Epoch 95/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1122 - val_loss: 0.1242\n",
            "Epoch 96/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1154\n",
            "Epoch 97/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.1250\n",
            "Epoch 98/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1027 - val_loss: 0.1241\n",
            "Epoch 99/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0986 - val_loss: 0.1120\n",
            "Epoch 100/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1100 - val_loss: 0.1097\n",
            "Epoch 101/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.1156\n",
            "Epoch 102/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.1233\n",
            "Epoch 103/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.1239\n",
            "Epoch 104/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0921 - val_loss: 0.1093\n",
            "Epoch 105/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0928 - val_loss: 0.1162\n",
            "Epoch 106/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.1142\n",
            "Epoch 107/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0992 - val_loss: 0.1194\n",
            "Epoch 108/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0987 - val_loss: 0.1159\n",
            "Epoch 109/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.1155\n",
            "Epoch 110/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0884 - val_loss: 0.1254\n",
            "Epoch 111/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1035 - val_loss: 0.1167\n",
            "Epoch 112/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.1278\n",
            "Epoch 113/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0866 - val_loss: 0.1227\n",
            "Epoch 114/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1008 - val_loss: 0.1133\n",
            "Epoch 115/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.1116\n",
            "Epoch 116/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0982 - val_loss: 0.1150\n",
            "Epoch 117/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0873 - val_loss: 0.1272\n",
            "Epoch 118/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0747 - val_loss: 0.1145\n",
            "Epoch 119/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0711 - val_loss: 0.1134\n",
            "Epoch 120/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0792 - val_loss: 0.1179\n",
            "Epoch 121/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0726 - val_loss: 0.1227\n",
            "Epoch 122/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0995 - val_loss: 0.1126\n",
            "Epoch 123/600\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 0.1098\n",
            "Epoch 124/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0780 - val_loss: 0.1191\n",
            "Epoch 125/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0891 - val_loss: 0.1213\n",
            "Epoch 126/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0965 - val_loss: 0.1163\n",
            "Epoch 127/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0689 - val_loss: 0.1198\n",
            "Epoch 128/600\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0860 - val_loss: 0.1366\n",
            "Epoch 129/600\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0775 - val_loss: 0.1315\n",
            "Epoch 00129: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff1a1479e50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iCqJJ7SkP6bh",
        "outputId": "f2008c70-1808-4989-ea05-b681420e9a6c"
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1a153bf90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P449k0HFud5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}